# llm_monitor.py
# LLMè°ƒç”¨ç›‘æ§å’Œæ—¥å¿—ç³»ç»Ÿ

import time
import json
import logging
from datetime import datetime
from typing import Optional, Dict, Any, List
from dataclasses import dataclass, asdict
from enum import Enum
import asyncio
from pathlib import Path

class LogLevel(Enum):
    """æ—¥å¿—çº§åˆ«æšä¸¾"""
    DEBUG = "DEBUG"
    INFO = "INFO"
    WARNING = "WARNING"
    ERROR = "ERROR"
    CRITICAL = "CRITICAL"

class LLMCallStatus(Enum):
    """LLMè°ƒç”¨çŠ¶æ€æšä¸¾"""
    SUCCESS = "success"
    FAILED = "failed"
    TIMEOUT = "timeout"
    RETRY = "retry"

@dataclass
class LLMCallRecord:
    """LLMè°ƒç”¨è®°å½•æ•°æ®ç±»"""
    call_id: str
    timestamp: str
    function_name: str
    model: str
    temperature: float
    top_p: float
    frequency_penalty: float
    presence_penalty: float
    system_message_length: int
    user_message_length: int
    response_length: int
    response_time: float
    attempt_count: int
    status: str
    error_message: Optional[str] = None
    stage: Optional[str] = None
    iteration_info: Optional[Dict] = None

class LLMMonitor:
    """LLMè°ƒç”¨ç›‘æ§å™¨"""
    
    def __init__(self, log_file: str = "llm_monitor.log", enable_console: bool = True):
        """
        åˆå§‹åŒ–LLMç›‘æ§å™¨
        
        Args:
            log_file (str): æ—¥å¿—æ–‡ä»¶è·¯å¾„
            enable_console (bool): æ˜¯å¦å¯ç”¨æ§åˆ¶å°è¾“å‡º
        """
        self.log_file = log_file
        self.enable_console = enable_console
        self.call_records: List[LLMCallRecord] = []
        self.session_stats = {
            "total_calls": 0,
            "successful_calls": 0,
            "failed_calls": 0,
            "total_response_time": 0.0,
            "total_input_tokens": 0,
            "total_output_tokens": 0
        }
        
        # å…ˆåˆ›å»ºæ—¥å¿—ç›®å½•ï¼Œé¿å…FileNotFoundError
        Path(log_file).parent.mkdir(parents=True, exist_ok=True)
        
        # è®¾ç½®æ—¥å¿—è®°å½•å™¨
        self._setup_logger()
    
    def _setup_logger(self):
        """è®¾ç½®æ—¥å¿—è®°å½•å™¨"""
        self.logger = logging.getLogger("LLMMonitor")
        self.logger.setLevel(logging.DEBUG)
        
        # æ¸…é™¤ç°æœ‰å¤„ç†å™¨
        self.logger.handlers.clear()
        
        # æ–‡ä»¶å¤„ç†å™¨
        file_handler = logging.FileHandler(self.log_file, encoding='utf-8')
        file_handler.setLevel(logging.DEBUG)
        
        # æ§åˆ¶å°å¤„ç†å™¨
        if self.enable_console:
            console_handler = logging.StreamHandler()
            console_handler.setLevel(logging.INFO)
            self.logger.addHandler(console_handler)
        
        # è®¾ç½®æ ¼å¼
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        file_handler.setFormatter(formatter)
        
        self.logger.addHandler(file_handler)
    
    def generate_call_id(self) -> str:
        """ç”Ÿæˆå”¯ä¸€çš„è°ƒç”¨ID"""
        return f"llm_{int(time.time() * 1000)}_{len(self.call_records)}"
    
    def log_call_start(self, call_id: str, function_name: str, model: str, 
                      system_message: str, user_message: str, 
                      temperature: float = 0.5, top_p: float = 0.95,
                      frequency_penalty: float = 0, presence_penalty: float = 0,
                      stage: str = None, iteration_info: Dict = None) -> None:
        """è®°å½•LLMè°ƒç”¨å¼€å§‹"""
        
        log_message = f" LLMè°ƒç”¨å¼€å§‹ [ID: {call_id}]"
        log_message += f"\n  é˜¶æ®µ: {stage or 'æœªæŒ‡å®š'}"
        log_message += f"\n  æ¨¡å‹: {model}"
        log_message += f"\n  å‡½æ•°: {function_name}"
        log_message += f"\n  å‚æ•°: T={temperature}, P={top_p}, FP={frequency_penalty}, PP={presence_penalty}"
        log_message += f"\n  è¾“å…¥é•¿åº¦: ç³»ç»Ÿæ¶ˆæ¯={len(system_message)}å­—ç¬¦, ç”¨æˆ·æ¶ˆæ¯={len(user_message)}å­—ç¬¦"
        
        if iteration_info:
            log_message += f"\n  è¿­ä»£ä¿¡æ¯: {iteration_info}"
        
        self.logger.info(log_message)
        
        # è¯¦ç»†è¾“å…¥å†…å®¹è®°å½•åˆ°DEBUGçº§åˆ«
        self.logger.debug(f"ç³»ç»Ÿæ¶ˆæ¯å†…å®¹ [ID: {call_id}]: {system_message[:200]}...")
        self.logger.debug(f"ç”¨æˆ·æ¶ˆæ¯å†…å®¹ [ID: {call_id}]: {user_message[:200]}...")
    
    def log_call_end(self, call_id: str, function_name: str, model: str,
                    system_message: str, user_message: str, response: Optional[str],
                    response_time: float, attempt_count: int, status: LLMCallStatus,
                    error_message: Optional[str] = None, stage: str = None,
                    iteration_info: Dict = None, temperature: float = 0.5, 
                    top_p: float = 0.95, frequency_penalty: float = 0, 
                    presence_penalty: float = 0) -> None:
        """è®°å½•LLMè°ƒç”¨ç»“æŸ"""
        
        # åˆ›å»ºè°ƒç”¨è®°å½•
        record = LLMCallRecord(
            call_id=call_id,
            timestamp=datetime.now().isoformat(),
            function_name=function_name,
            model=model,
            temperature=temperature,
            top_p=top_p,
            frequency_penalty=frequency_penalty,
            presence_penalty=presence_penalty,
            system_message_length=len(system_message),
            user_message_length=len(user_message),
            response_length=len(response) if response else 0,
            response_time=response_time,
            attempt_count=attempt_count,
            status=status.value,
            error_message=error_message,
            stage=stage,
            iteration_info=iteration_info
        )
        
        self.call_records.append(record)
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        self._update_stats(record)
        
        # è®°å½•æ—¥å¿—
        status_emoji = "æˆåŠŸ" if status == LLMCallStatus.SUCCESS else "å¤±è´¥"
        log_message = f"{status_emoji} LLMè°ƒç”¨å®Œæˆ [ID: {call_id}]"
        log_message += f"\n  é˜¶æ®µ: {stage or 'æœªæŒ‡å®š'}"
        log_message += f"\n  æ¨¡å‹: {model}"
        log_message += f"\n  å‡½æ•°: {function_name}"
        log_message += f"\n  â±å“åº”æ—¶é—´: {response_time:.2f}ç§’"
        log_message += f"\n  å°è¯•æ¬¡æ•°: {attempt_count}"
        log_message += f"\n  è¾“å‡ºé•¿åº¦: {len(response) if response else 0}å­—ç¬¦"
        log_message += f"\n  çŠ¶æ€: {status.value}"
        
        if error_message:
            log_message += f"\n  é”™è¯¯: {error_message}"
        
        if iteration_info:
            log_message += f"\n  è¿­ä»£ä¿¡æ¯: {iteration_info}"
        
        if status == LLMCallStatus.SUCCESS:
            self.logger.info(log_message)
            # è¯¦ç»†å“åº”å†…å®¹è®°å½•åˆ°DEBUGçº§åˆ«
            if response:
                self.logger.debug(f"å“åº”å†…å®¹ [ID: {call_id}]: {response[:200]}...")
        else:
            self.logger.error(log_message)
    
    def _update_stats(self, record: LLMCallRecord) -> None:
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        self.session_stats["total_calls"] += 1
        self.session_stats["total_response_time"] += record.response_time
        self.session_stats["total_input_tokens"] += record.system_message_length + record.user_message_length
        self.session_stats["total_output_tokens"] += record.response_length
        
        if record.status == LLMCallStatus.SUCCESS.value:
            self.session_stats["successful_calls"] += 1
        else:
            self.session_stats["failed_calls"] += 1
    
    def log_workflow_stage(self, stage: str, description: str, level: LogLevel = LogLevel.INFO) -> None:
        """è®°å½•å·¥ä½œæµé˜¶æ®µä¿¡æ¯"""
        log_message = f" å·¥ä½œæµé˜¶æ®µ: {stage}\n   æè¿°: {description}"
        
        if level == LogLevel.DEBUG:
            self.logger.debug(log_message)
        elif level == LogLevel.INFO:
            self.logger.info(log_message)
        elif level == LogLevel.WARNING:
            self.logger.warning(log_message)
        elif level == LogLevel.ERROR:
            self.logger.error(log_message)
        elif level == LogLevel.CRITICAL:
            self.logger.critical(log_message)

    def log_stage_context(self, stage: str, context: Dict[str, Any], level: LogLevel = LogLevel.DEBUG) -> None:
        """
        è®°å½•ç»“æ„åŒ–çš„é˜¶æ®µä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä¾¿äºåç»­åˆ†æè¿­ä»£åŸå› ä¸æ•°æ®æµåŠ¨æ€ã€‚
        
        å‚æ•°:
            stage (str): å½“å‰é˜¶æ®µæ ‡è¯†ï¼Œä¾‹å¦‚ "macro_review.pre", "macro_review.decision" ç­‰ã€‚
            context (Dict[str, Any]): éœ€è¦è®°å½•çš„ä¸Šä¸‹æ–‡å­—æ®µï¼Œå»ºè®®ä¸ºå¯JSONåºåˆ—åŒ–çš„å­—å…¸ã€‚
            level (LogLevel): æ—¥å¿—çº§åˆ«ï¼Œé»˜è®¤DEBUGä»¥é¿å…å¹²æ‰°å¸¸è§„INFOè¾“å‡ºã€‚
        """
        try:
            payload = {
                "stage": stage,
                "context": context
            }
            msg = json.dumps(payload, ensure_ascii=False, indent=2)
        except Exception:
            # å…œåº•ï¼šå¦‚æœä¸å¯åºåˆ—åŒ–ï¼Œé€€åŒ–ä¸ºå­—ç¬¦ä¸²è¾“å‡º
            msg = f"stage={stage} context={str(context)}"
        
        if level == LogLevel.DEBUG:
            self.logger.debug(msg)
        elif level == LogLevel.INFO:
            self.logger.info(msg)
        elif level == LogLevel.WARNING:
            self.logger.warning(msg)
        elif level == LogLevel.ERROR:
            self.logger.error(msg)
        elif level == LogLevel.CRITICAL:
            self.logger.critical(msg)
    
    def get_session_stats(self) -> Dict[str, Any]:
        """è·å–ä¼šè¯ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.session_stats.copy()
        if stats["total_calls"] > 0:
            stats["success_rate"] = stats["successful_calls"] / stats["total_calls"] * 100
            stats["average_response_time"] = stats["total_response_time"] / stats["total_calls"]
        else:
            stats["success_rate"] = 0
            stats["average_response_time"] = 0
        
        return stats
    
    def print_session_summary(self) -> None:
        """æ‰“å°ä¼šè¯æ‘˜è¦"""
        stats = self.get_session_stats()
        
        summary = f"""
{'='*60}
ğŸ“Š LLMè°ƒç”¨ä¼šè¯æ‘˜è¦
{'='*60}
 æ€»è°ƒç”¨æ¬¡æ•°: {stats['total_calls']}
 æˆåŠŸè°ƒç”¨: {stats['successful_calls']}
 å¤±è´¥è°ƒç”¨: {stats['failed_calls']}
 æˆåŠŸç‡: {stats['success_rate']:.1f}%
â± å¹³å‡å“åº”æ—¶é—´: {stats['average_response_time']:.2f}ç§’
 æ€»è¾“å…¥å­—ç¬¦: {stats['total_input_tokens']:,}
 æ€»è¾“å‡ºå­—ç¬¦: {stats['total_output_tokens']:,}
{'='*60}
"""
        
        print(summary)
        self.logger.info(summary)
    
    def export_records_to_json(self, filename: str = None) -> str:
        """å¯¼å‡ºè°ƒç”¨è®°å½•åˆ°JSONæ–‡ä»¶"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"llm_records_{timestamp}.json"
        
        records_data = {
            "session_stats": self.get_session_stats(),
            "call_records": [asdict(record) for record in self.call_records]
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(records_data, f, ensure_ascii=False, indent=2)
        
        self.logger.info(f"è°ƒç”¨è®°å½•å·²å¯¼å‡ºåˆ°: {filename}")
        return filename

# å…¨å±€ç›‘æ§å™¨å®ä¾‹
_global_monitor: Optional[LLMMonitor] = None

def get_global_monitor() -> LLMMonitor:
    """è·å–å…¨å±€LLMç›‘æ§å™¨å®ä¾‹"""
    global _global_monitor
    if _global_monitor is None:
        # ä½¿ç”¨ç»å¯¹è·¯å¾„ç¡®ä¿æ—¥å¿—æ–‡ä»¶èƒ½å¤Ÿæ­£ç¡®åˆ›å»º
        import os
        current_dir = os.path.dirname(os.path.abspath(__file__))
        log_file_path = os.path.join(current_dir, "logs", "llm_monitor.log")
        _global_monitor = LLMMonitor(
            log_file=log_file_path,
            enable_console=True
        )
    return _global_monitor

def initialize_monitor(log_file: str = None, enable_console: bool = True) -> LLMMonitor:
    """åˆå§‹åŒ–å…¨å±€ç›‘æ§å™¨"""
    global _global_monitor
    if log_file is None:
        # ä½¿ç”¨ç»å¯¹è·¯å¾„ç¡®ä¿æ—¥å¿—æ–‡ä»¶èƒ½å¤Ÿæ­£ç¡®åˆ›å»º
        import os
        current_dir = os.path.dirname(os.path.abspath(__file__))
        log_file = os.path.join(current_dir, "logs", "llm_monitor.log")
    _global_monitor = LLMMonitor(log_file, enable_console)
    return _global_monitor